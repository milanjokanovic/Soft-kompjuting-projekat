{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "import math\n",
    "import sys\n",
    "import io\n",
    "from collections import defaultdict\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = 16,12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path):\n",
    "    return cv2.cvtColor(cv2.imread(path), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def image_gray(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "def invert(image):\n",
    "    return 255-image\n",
    "\n",
    "def display_image(image, color=False):\n",
    "    if color:\n",
    "        plt.imshow(image)\n",
    "    else:\n",
    "        plt.imshow(image, 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_region(region):\n",
    "    return cv2.resize(region, (28, 28), interpolation=cv2.INTER_NEAREST)\n",
    "def resizeImg(img):\n",
    "    h, w, ch = img.shape\n",
    "    height = math.ceil(h/400)\n",
    "    width = math.ceil(w/900)\n",
    "    \n",
    "    resize = 0\n",
    "    if(width > height):\n",
    "        resize = width\n",
    "    else:\n",
    "        resize = height\n",
    "        \n",
    "    resized = cv2.resize(img, None, fx = 1/resize, fy = 1/resize)\n",
    "    \n",
    "    return resized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_roi(image_orig, image_bin):\n",
    "    contours, hierarchy = cv2.findContours(image_bin.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    sorted_regions = []\n",
    "    regions_array = []\n",
    "    pom = 0\n",
    "    \n",
    "    rows, cols, ch = image_orig.shape\n",
    "    widthMax = math.floor(cols / 15)\n",
    "    widthMin = widthMax / 3\n",
    "    heigthMax = 35 * widthMax / 48\n",
    "    heigthMin = 2 * heigthMax / 3\n",
    "    \n",
    "    prevDist = 0\n",
    "    prevX = 0\n",
    "    prevY = 0\n",
    "    minY = rows\n",
    "    minX = cols\n",
    "    realY = 0\n",
    "    false_countours = []\n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        area = cv2.contourArea(contour)\n",
    "        if area > heigthMin and h < heigthMax and h > heigthMin and w > widthMin and w < widthMax:\n",
    "            indeks = 0\n",
    "            for contour1 in contours:\n",
    "                x1, y1, w1, h1 = cv2.boundingRect(contour1)\n",
    "                area = cv2.contourArea(contour1)\n",
    "                \n",
    "                if area > heigthMin and h < heigthMax and h > heigthMin and w > widthMin and w < widthMax:\n",
    "                    if((x < x1 or x + w > x1) and y != y1):\n",
    "                        pom = 0\n",
    "                        for false in false_countours:\n",
    "                            if(false == indeks):\n",
    "                                pom = 1\n",
    "                        if(pom == 0):\n",
    "                            false_countours.append(indeks)\n",
    "                        break\n",
    "                    \n",
    "                indeks = indeks + 1\n",
    "\n",
    "    \n",
    "    false_countours.sort(reverse=True) \n",
    "    for false in false_countours:\n",
    "        contours.pop(false)\n",
    "    \n",
    "    for contour in contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        area = cv2.contourArea(contour)\n",
    "        \n",
    "        if area > heigthMin and h < heigthMax and h > heigthMin and w > widthMin and w < widthMax:\n",
    "            region = image_bin[y:y+h+1, x:x+w+1]\n",
    "            regions_array.append([resize_region(region), (x, y, w, h)])\n",
    "            cv2.rectangle(image_orig, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    regions_array = sorted(regions_array, key=lambda x: x[1][0])\n",
    "    sorted_regions = [region[0] for region in regions_array]\n",
    "    return image_orig, sorted_regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shearMatrix(pt1, pt2):\n",
    "    return cv2.getAffineTransform(pt1, pt2)\n",
    "def shearImg(img_color, src):\n",
    "    \n",
    "    dst = cv2.Canny(src, 50, 200, None, 3)\n",
    "    \n",
    "    cdst = cv2.cvtColor(dst, cv2.COLOR_GRAY2BGR)\n",
    "    cdstP = np.copy(cdst)\n",
    "    \n",
    "    lines = cv2.HoughLines(dst, 1, np.pi / 180, 150, None, 0, 0)\n",
    "    \n",
    "    maxLine = 0\n",
    "            \n",
    "    \n",
    "    \n",
    "    linesP = cv2.HoughLinesP(dst, 1, np.pi / 180, 50, None, 50, 10)\n",
    "    l = linesP[0][0]\n",
    "    \n",
    "    if linesP is not None:\n",
    "        for i in range(0, len(linesP)):\n",
    "            l1 = linesP[i][0]\n",
    "            lineLength = abs(l1[0] - l1[2])\n",
    "            if(lineLength > maxLine):\n",
    "                l = l1\n",
    "                maxLine = lineLength\n",
    "    \n",
    "    cv2.line(cdstP, (l[0], l[1]), (l[2], l[3]), (0,0,255), 3, cv2.LINE_AA)\n",
    "    \n",
    "    \n",
    "    \n",
    "    rows, cols = src.shape\n",
    "    beginPoint = [l[0], l[3]]\n",
    "    \n",
    "    if(l[1] == l[3]):\n",
    "        beginPoint = [0,0]\n",
    "    pts1 = np.float32([ beginPoint, [l[0], l[1]], [l[2], l[3]]])\n",
    "    pts2 = np.float32([ beginPoint, [l[0], l[1]], [l[2], l[1]]])\n",
    "    \n",
    "    matrix = shearMatrix(pts1, pts2)\n",
    "    \n",
    "    sheared_color = cv2.warpAffine(img_color, matrix, (cols, rows))\n",
    "    sheared = cv2.warpAffine(src, matrix, (cols, rows))\n",
    "    \n",
    "    \n",
    "    return sheared, sheared_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_bin(image_gs, ind):\n",
    "    height, width = image_gs.shape[0:2]\n",
    "    image_binary = np.ndarray((height, width), dtype=np.uint8)\n",
    "    if(ind == 0):\n",
    "        image_bin = cv2.adaptiveThreshold(image_gs, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 23, 1)\n",
    "    else:\n",
    "        ret, image_bin = cv2.threshold(image_gs, 110, 255, cv2.THRESH_BINARY)\n",
    "    return image_bin\n",
    "\n",
    "def dilate(image):\n",
    "    kernel = np.ones((1, 1))\n",
    "    return cv2.dilate(image, kernel, iterations=1)\n",
    "\n",
    "def erode(image):\n",
    "    kernel = np.ones((2, 2))\n",
    "    return cv2.erode(image, kernel, iterations=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_to_range(image):\n",
    "    return image/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_to_vector(image):\n",
    "    return image.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_ann(regions):\n",
    "    ready_for_ann = []\n",
    "    for region in regions:\n",
    "        scale = scale_to_range(region)\n",
    "        ready_for_ann.append(matrix_to_vector(scale))\n",
    "    return ready_for_ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_output(alphabet):\n",
    "    nn_outputs = []\n",
    "    for index in range(len(alphabet)):\n",
    "        output = np.zeros(len(alphabet))\n",
    "        output[index] = 1\n",
    "        nn_outputs.append(output)\n",
    "    return np.array(nn_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ann(output_size):\n",
    "    ann = Sequential()\n",
    "    ann.add(Dense(128, input_dim=784, activation='sigmoid'))\n",
    "    ann.add(Dense(output_size, activation='sigmoid'))\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_ann(ann, X_train, y_train, epochs):\n",
    "    X_train = np.array(X_train, np.float32) # dati ulaz\n",
    "    y_train = np.array(y_train, np.float32) # zeljeni izlazi na date ulaze\n",
    "    \n",
    "    print(\"\\nTraining started...\")\n",
    "    sgd = SGD(lr=0.01, momentum=0.9)\n",
    "    ann.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "    ann.fit(X_train, y_train, epochs=epochs, batch_size=1, verbose=0, shuffle=False)\n",
    "    print(\"\\nTraining completed...\")\n",
    "    return ann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winner(output):\n",
    "    return max(enumerate(output), key=lambda x: x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_result(outputs, alphabet):\n",
    "    result = []\n",
    "    for output in outputs:\n",
    "        result.append(alphabet[winner(output)])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(word):\n",
    "    return [char for char in word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "480\n"
     ]
    }
   ],
   "source": [
    "sredjenaSlova = []\n",
    "with io.open(\"train-data-set\\data-info.txt\", \"r\", encoding=\"utf-8\") as my_file:\n",
    "    my_unicode_string = my_file.readlines()\n",
    "    #print(my_unicode_string)\n",
    "    for ln in my_unicode_string:\n",
    "        parts = ln.split('|')\n",
    "        letters = split(parts[2])\n",
    "\n",
    "        if(len(letters) > 12):\n",
    "            for i in range(0, len(letters)-1):\n",
    "                if(letters[i] == 'n' and letters[i+1] == 'j'):\n",
    "                    letters[i] = letters[i]+letters[i+1]\n",
    "                    del letters[i+1]\n",
    "                    if(len(letters) == 12):\n",
    "                        break\n",
    "                if (letters[i] == 'l' and letters[i + 1] == 'j'):\n",
    "                    letters[i] = letters[i] + letters[i + 1]\n",
    "                    del letters[i + 1]\n",
    "                    if (len(letters) == 12):\n",
    "                        break\n",
    "                if (letters[i] == 'd' and letters[i + 1] == u'ž'):\n",
    "                    letters[i] = letters[i] + letters[i + 1]\n",
    "                    del letters[i + 1]\n",
    "                    if (len(letters) == 12):\n",
    "                        break\n",
    "\n",
    "        sredjenaSlova.append(letters)\n",
    "print(len(sredjenaSlova))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukupno  368\n",
      "Sto  100\n",
      "Dvesto  99\n",
      "Tristo  94\n",
      "Ostalo  75\n",
      "Telefon  0\n"
     ]
    }
   ],
   "source": [
    "ukupno = 0\n",
    "sto = 0\n",
    "dvesto = 0\n",
    "tristo = 0\n",
    "ostalo = 0\n",
    "telefon = 0\n",
    "\n",
    "wholeAlphabet = {'a':[], 'b':[], 'c':[], 'č':[], 'ć':[], 'd':[], 'dž':[], 'đ':[], 'e':[], 'f':[], 'g':[], 'h':[],\n",
    "                'i':[], 'j':[], 'k':[], 'l':[], 'lj':[], 'm':[], 'n':[], 'nj':[], 'o':[], 'p':[], 'r':[], 's':[],\n",
    "                'š':[], 't':[], 'u':[], 'v':[], 'z':[], 'ž':[]}\n",
    "\n",
    "mostReccuringPixel = {'a':[], 'b':[], 'c':[], 'č':[], 'ć':[], 'd':[], 'dž':[], 'đ':[], 'e':[], 'f':[], 'g':[], 'h':[],\n",
    "                'i':[], 'j':[], 'k':[], 'l':[], 'lj':[], 'm':[], 'n':[], 'nj':[], 'o':[], 'p':[], 'r':[], 's':[],\n",
    "                'š':[], 't':[], 'u':[], 'v':[], 'z':[], 'ž':[]}\n",
    "\n",
    "dim = (28,28)\n",
    "for key, value in mostReccuringPixel.items():\n",
    "    mostReccuringPixel[key] = np.zeros(dim)\n",
    "for key, value in wholeAlphabet.items():\n",
    "    wholeAlphabet[key] = np.zeros(dim)\n",
    "#print(mostReccuringPixel)\n",
    "\n",
    "for i in range(1, 400):\n",
    "    extension = '.png'\n",
    "    if(i >= 400):\n",
    "        extension = '.jpg'\n",
    "    img_name = 'img' + str(i) + extension\n",
    "    image_color = load_image('train-data-set/data-images/' + img_name)\n",
    "    image_color = resizeImg(image_color)\n",
    "    img_gray = image_gray(image_color)\n",
    "    img_shear, image_color = shearImg(image_color, img_gray)\n",
    "    img = image_bin(img_shear, 1)\n",
    "    img_bin = dilate(erode(img))\n",
    "    selected_regions, numbers = select_roi(image_color.copy(), img_bin)\n",
    "    if(len(numbers) != 12):\n",
    "        #cv2.imshow(\"Selected image\" + str(i), selected_regions)\n",
    "        #cv2.waitKey()\n",
    "        image_color = load_image('train-data-set/data-images/' + img_name)\n",
    "        image_color = resizeImg(image_color)\n",
    "        img_gray = image_gray(image_color)\n",
    "        img_shear, image_color = shearImg(image_color, img_gray)\n",
    "        img = image_bin(img_shear, 0)\n",
    "        img_bin = dilate(erode(img))\n",
    "        selected_regions, numbers = select_roi(image_color.copy(), img_bin)\n",
    "        if(len(numbers) != 12):\n",
    "            #cv2.imshow(\"Fail Selected image\" + str(i), selected_regions)\n",
    "            #cv2.waitKey()\n",
    "            continue\n",
    "    if(len(numbers) == 12):\n",
    "        #cv2.imshow(\"Selected image\" + str(i), selected_regions)\n",
    "        #cv2.waitKey()\n",
    "        ukupno = ukupno + 1\n",
    "        if(i <= 100):\n",
    "            sto = sto + 1\n",
    "        elif(i <= 200 and i > 100):\n",
    "            dvesto = dvesto + 1\n",
    "        elif(i <= 300 and i > 200):\n",
    "            tristo = tristo + 1\n",
    "        elif(i <= 400 and i > 300):\n",
    "            ostalo = ostalo + 1\n",
    "        else:\n",
    "            telefon = telefon + 1\n",
    "            \n",
    "    alphabet = sredjenaSlova[i-1]\n",
    "    \n",
    "    for i in range(0, len(numbers)):\n",
    "        #print(numbers[i])\n",
    "        for j in range(0, 28):\n",
    "            for k in range(0, 28):\n",
    "                if(numbers[i][j][k] == 0):\n",
    "                    mostReccuringPixel[alphabet[i]][j][k] -= 1\n",
    "                else:\n",
    "                    mostReccuringPixel[alphabet[i]][j][k] += 1\n",
    "    \n",
    "print(\"Ukupno \", ukupno)\n",
    "print(\"Sto \", sto)\n",
    "print(\"Dvesto \", dvesto)\n",
    "print(\"Tristo \", tristo)\n",
    "print(\"Ostalo \", ostalo)\n",
    "print(\"Telefon \", telefon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'b', 'c', 'č', 'ć', 'd', 'dž', 'đ', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'lj', 'm', 'n', 'nj', 'o', 'p', 'r', 's', 'š', 't', 'u', 'v', 'z', 'ž']\n"
     ]
    }
   ],
   "source": [
    "for key, value in wholeAlphabet.items():\n",
    "    for j in range(0, 28):\n",
    "        for k in range(0, 28):\n",
    "            if(mostReccuringPixel[key][j][k] <= 0):\n",
    "                wholeAlphabet[key][j][k] = 0\n",
    "            else:\n",
    "                wholeAlphabet[key][j][k] = 255\n",
    "#print(\"ovo\")     \n",
    "#print(wholeAlphabet)\n",
    "    \n",
    "testAlph = []\n",
    "prepInput = []\n",
    "\n",
    "for key, value in wholeAlphabet.items():\n",
    "    if len(value) != 0:\n",
    "        #print(key)\n",
    "        testAlph.append(key)\n",
    "        prepInput.append(value)\n",
    "#print(prepInput)\n",
    "print(testAlph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training started...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-94-3fdf2344dd9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#print(outputs)u\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mann\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_ann\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestAlph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mann\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_ann\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mann\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m11000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-3a99ed997662>\u001b[0m in \u001b[0;36mtrain_ann\u001b[1;34m(ann, X_train, y_train, epochs)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0msgd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mann\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nTraining completed...\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mann\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python 3.6\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32md:\\python 3.6\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python 3.6\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python 3.6\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python 3.6\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python 3.6\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python 3.6\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32md:\\python 3.6\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inputs = prepare_for_ann(prepInput)\n",
    "#print(numbers[0])\n",
    "outputs = convert_output(testAlph)\n",
    "#print(outputs)u\n",
    "ann = create_ann(output_size=len(testAlph))\n",
    "ann = train_ann(ann, inputs, outputs, epochs=11000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sredjenaSlovaTest = []\n",
    "with io.open(\"test-data-set\\data-info.txt\", \"r\", encoding=\"utf-8\") as my_file:\n",
    "    my_unicode_string = my_file.readlines()\n",
    "    #print(my_unicode_string)\n",
    "    for ln in my_unicode_string:\n",
    "        parts = ln.split('|')\n",
    "        letters = split(parts[2])\n",
    "\n",
    "        if(len(letters) > 12):\n",
    "            for i in range(0, len(letters)-1):\n",
    "                if(letters[i] == 'n' and letters[i+1] == 'j'):\n",
    "                    letters[i] = letters[i]+letters[i+1]\n",
    "                    del letters[i+1]\n",
    "                    if(len(letters) == 12):\n",
    "                        break\n",
    "                if (letters[i] == 'l' and letters[i + 1] == 'j'):\n",
    "                    letters[i] = letters[i] + letters[i + 1]\n",
    "                    del letters[i + 1]\n",
    "                    if (len(letters) == 12):\n",
    "                        break\n",
    "                if (letters[i] == 'd' and letters[i + 1] == u'ž'):\n",
    "                    letters[i] = letters[i] + letters[i + 1]\n",
    "                    del letters[i + 1]\n",
    "                    if (len(letters) == 12):\n",
    "                        break\n",
    "\n",
    "        sredjenaSlovaTest.append(letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success:37\n",
      "failure:21\n"
     ]
    }
   ],
   "source": [
    "success = 0\n",
    "failure = 0\n",
    "foundLetters = []\n",
    "\n",
    "for i in range(1, 61):\n",
    "    extension = '.png'\n",
    "    \n",
    "    img_name = 'img' + str(i) + extension\n",
    "    image_color = load_image('test-data-set/data-images/' + img_name)\n",
    "    image_color = resizeImg(image_color)\n",
    "    img_gray = image_gray(image_color)\n",
    "    img_shear, image_color = shearImg(image_color, img_gray)\n",
    "    img = image_bin(img_shear, 1)\n",
    "    img_bin = dilate(erode(img))\n",
    "    selected_regions, test_numbers = select_roi(image_color.copy(), img_bin)\n",
    "    if(len(test_numbers) != 12):\n",
    "        #cv2.imshow(\"Selected image\" + str(i), selected_regions)\n",
    "        #cv2.waitKey()\n",
    "        image_color = load_image('test-data-set/data-images/' + img_name)\n",
    "        image_color = resizeImg(image_color)\n",
    "        img_gray = image_gray(image_color)\n",
    "        img_shear, image_color = shearImg(image_color, img_gray)\n",
    "        img = image_bin(img_shear, 0)\n",
    "        img_bin = dilate(erode(img))\n",
    "        selected_regions, test_numbers = select_roi(image_color.copy(), img_bin)\n",
    "        if(len(test_numbers) != 12):\n",
    "            #cv2.imshow(\"Fail Selected image\" + str(i), selected_regions)\n",
    "            #cv2.waitKey()\n",
    "            continue\n",
    "            \n",
    "    alphabet = sredjenaSlovaTest[i-1]\n",
    "    test_inputs =  prepare_for_ann(test_numbers)\n",
    "    #print(test_inputs)\n",
    "    result = ann.predict(np.array(test_inputs, np.float32))\n",
    "    \n",
    "    pom = display_result(result, testAlph)\n",
    "    ind = 0\n",
    "    \n",
    "    for i in range(0, len(pom)):\n",
    "        if(pom[i] != alphabet[i]):\n",
    "            failure += 1\n",
    "            ind = 1\n",
    "            break\n",
    "            \n",
    "    if ind == 0:\n",
    "        foundLetters.append(\"\".join(pom))\n",
    "        success += 1\n",
    "        \n",
    "print(\"success:\" + str(success))\n",
    "print(\"failure:\" + str(failure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['orijentacija']\n",
      "['dobrodošlica']\n",
      "['saobraćajac']\n",
      "['idealistički']\n",
      "['kakofonija']\n",
      "['profesorski']\n",
      "['prepešačiti']\n",
      "['podrhtavati']\n",
      "['sekretarijat']\n",
      "['komparativno']\n",
      "['hipertenzija']\n",
      "['dugometražni']\n",
      "['simpatizer']\n",
      "['obezbeđenje']\n",
      "['kapitulirati']\n",
      "['emancipacija']\n",
      "['prisiljavati']\n",
      "['snajperista']\n",
      "['trbuhozborac']\n",
      "['restriktivno']\n",
      "['maloletnik']\n",
      "['matematičar']\n",
      "['kompromisi']\n",
      "['obračunavati']\n",
      "['hortikultura']\n",
      "['propovedati']\n",
      "['izrezbariti']\n",
      "['predosećanje']\n",
      "['uspavljivati']\n",
      "['razbarušena']\n",
      "['pirotehničar']\n",
      "['silovitost']\n",
      "['maliciznost']\n",
      "['kontraverz']\n",
      "['naglašavati']\n",
      "['beznačajno']\n",
      "['elektronika']\n"
     ]
    }
   ],
   "source": [
    "testData = []\n",
    "trainData = []\n",
    "#validateData = []\n",
    "\n",
    "with io.open(\"test-data-set\\data-info.txt\", \"r\", encoding=\"utf-8\") as my_file:\n",
    "    my_unicode_string = my_file.readlines()\n",
    "    #print(my_unicode_string)\n",
    "    for ln in my_unicode_string:\n",
    "        word = ln.split('|')[1]\n",
    "        testData.append(word)\n",
    "\n",
    "with io.open(\"train-data-set\\data-info.txt\", \"r\", encoding=\"utf-8\") as my_file:\n",
    "    my_unicode_string = my_file.readlines()\n",
    "    #print(my_unicode_string)\n",
    "    for ln in my_unicode_string:\n",
    "        word = ln.split('|')[1]\n",
    "        trainData.append(word)\n",
    "\n",
    "'''with io.open(\"validate-data-set\\data-info.txt\", \"r\", encoding=\"utf-8\") as my_file:\n",
    "    my_unicode_string = my_file.readlines()\n",
    "    #print(my_unicode_string)\n",
    "    for ln in my_unicode_string:\n",
    "        word = ln.split('|')[1]\n",
    "        validateData.append(word)'''\n",
    "word_dict = defaultdict(list)\n",
    "for word in testData:\n",
    "    for i in range(12, 7, -1):\n",
    "        for subset in itertools.combinations(word, i):\n",
    "            word_dict[''.join(sorted(subset))].append(\"\".join(subset))\n",
    "            #print (\"\".join(subset))\n",
    "\n",
    "\n",
    "for el in foundLetters:\n",
    "    ind = 0\n",
    "    for i in range(12, 7, -1):\n",
    "        if(ind==1):\n",
    "            break\n",
    "        for subset in itertools.combinations(el, i):\n",
    "            sorted_anagram = ''.join(sorted(subset))\n",
    "            if(word_dict.get(sorted_anagram) is not None):\n",
    "                print (word_dict.get(sorted_anagram))\n",
    "                ind = 1\n",
    "            if(ind==1):\n",
    "                break\n",
    "#print(len(word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
